from datetime import datetime
from aiogram import types, Bot
from aiogram.fsm.context import FSMContext
from io import BytesIO
from aiogram.types import BufferedInputFile

from src.keyboards.keyboards import get_main_keyboard, get_cancel_keyboard, get_generation_response_keyboard, get_audio_generation_options_keyboard, get_voice_selection_keyboard
from src.utils.message import safe_edit_message
from src.utils.user_data import get_user_stats, get_menu_text, update_user_stats
from src.utils.pollinations import generate_text, generate_image, generate_audio
from src.states.user import UserState
from config.config import AVAILABLE_VOICES

async def start_image_generation(callback: types.CallbackQuery, state: FSMContext):
    user_id = callback.from_user.id
    stats = get_user_stats(user_id)
    
    if not stats.get("current_model"):
        await safe_edit_message(
            callback.message,
            "‚ùó –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üé® –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'",
            reply_markup=get_main_keyboard()
        )
        await callback.answer()
        return
    
    if stats.get("model_type") != "image":
        await safe_edit_message(
            callback.message,
            "‚ùó –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üé® –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'",
            reply_markup=get_main_keyboard()
        )
        await callback.answer()
        return
    
    await safe_edit_message(
        callback.message,
        "–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å:",
        reply_markup=get_cancel_keyboard()
    )
    await state.set_state(UserState.waiting_for_image_prompt)
    await callback.answer()

async def start_text_generation(callback: types.CallbackQuery, state: FSMContext):
    user_id = callback.from_user.id
    stats = get_user_stats(user_id)
    
    if not stats.get("current_model"):
        await safe_edit_message(
            callback.message,
            "‚ùó –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üìù –¢–µ–∫—Å—Ç'",
            reply_markup=get_main_keyboard()
        )
        await callback.answer()
        return
    
    if stats.get("model_type") != "text":
        await safe_edit_message(
            callback.message,
            "‚ùó –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üìù –¢–µ–∫—Å—Ç'",
            reply_markup=get_main_keyboard()
        )
        await callback.answer()
        return
    
    await safe_edit_message(
        callback.message,
        "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å. –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ –≤–º–µ—Å—Ç–µ —Å —Ç–µ–∫—Å—Ç–æ–º:",
        reply_markup=get_cancel_keyboard()
    )
    await state.set_state(UserState.waiting_for_text_prompt)
    await callback.answer()

async def start_audio_generation(callback: types.CallbackQuery, state: FSMContext):
    await safe_edit_message(
        callback.message,
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ:",
        reply_markup=get_audio_generation_options_keyboard()
    )
    await state.set_state(UserState.waiting_for_audio_generation_type)
    await callback.answer()

async def start_echo_audio_generation(callback: types.CallbackQuery, state: FSMContext):
    await safe_edit_message(
        callback.message,
        "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è:",
        reply_markup=get_cancel_keyboard()
    )
    await state.set_state(UserState.waiting_for_audio_prompt)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∏–ø –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    await state.update_data(audio_gen_type="echo")
    await callback.answer()

async def start_response_audio_generation(callback: types.CallbackQuery, state: FSMContext):
    await safe_edit_message(
        callback.message,
        "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞—É–¥–∏–æ –æ—Ç–≤–µ—Ç–∞:",
        reply_markup=get_cancel_keyboard()
    )
    await state.set_state(UserState.waiting_for_audio_prompt)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∏–ø –∞—É–¥–∏–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    await state.update_data(audio_gen_type="response")
    await callback.answer()

async def process_image_prompt(message: types.Message, state: FSMContext, bot: Bot):
    user_id = message.from_user.id
    stats = get_user_stats(user_id)
    model = stats["current_model"]
    
    status_message = await message.answer("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
    
    image_url = await generate_image(model, message.text)
    if image_url:
        stats["images_generated"] += 1
        stats["last_used"] = datetime.now()
        update_user_stats(user_id, stats)
        
        await message.answer_photo(
            photo=image_url,
            caption=f"‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n–ü—Ä–æ–º–ø—Ç: {message.text}"
        )
        await message.answer(get_menu_text(user_id), reply_markup=get_main_keyboard())
    else:
        await message.answer(
            "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
            reply_markup=get_main_keyboard()
        )
    
    await status_message.delete()
    await state.clear()

async def process_text_prompt(message: types.Message, state: FSMContext, bot: Bot):
    user_id = message.from_user.id
    stats = get_user_stats(user_id)
    model = stats["current_model"]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
    image_data_bytes = None
    prompt_text = message.text

    if message.photo:
        photo = message.photo[-1]  # –ë–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data_io = await bot.download(photo.file_id)
        # –ß–∏—Ç–∞–µ–º –±–∞–π—Ç—ã –∏–∑ BytesIO –æ–±—ä–µ–∫—Ç–∞
        image_data_bytes = image_data_io.read()
        # –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ñ–æ—Ç–æ, —Ç–µ–∫—Å—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–æ–¥–ø–∏—Å–∏ (caption)
        prompt_text = message.caption

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –ø–æ–¥–ø–∏—Å–∏
    if not prompt_text:
        await message.answer(
            "‚ùó –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–ø–∏—Å—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é",
            reply_markup=get_cancel_keyboard()
        )
        return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ FSM
    await state.update_data(last_prompt_text=prompt_text, last_image_data=image_data_bytes)

    status_message = await message.answer(
        "üìù –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ..." +
        ("\nüñº –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..." if image_data_bytes else "")
    )

    # –ü–µ—Ä–µ–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–∞–π—Ç–∞—Ö –∏ —Ç–µ–∫—Å—Ç –≤ —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    response = await generate_text(model, prompt_text, image_data_bytes, user_id)
    if response:
        stats["texts_generated"] += 1
        stats["last_used"] = datetime.now()
        update_user_stats(user_id, stats)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        await status_message.edit_text(
            f"‚ú® –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ <b>{model}</b>:\n\n{response}",
            parse_mode="HTML",
            reply_markup=get_generation_response_keyboard()
        )
        # –ù–µ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –æ—Å—Ç–∞–µ–º—Å—è –≤ –æ–∂–∏–¥–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞

    else:
        await status_message.edit_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            reply_markup=get_main_keyboard()
        )
        await state.clear() # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ

async def process_audio_prompt(message: types.Message, state: FSMContext, bot: Bot):
    user_id = message.from_user.id
    stats = get_user_stats(user_id)
    prompt_text = message.text

    if not prompt_text:
        await message.answer(
            "‚ùó –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è",
            reply_markup=get_cancel_keyboard()
        )
        return

    data = await state.get_data()
    audio_gen_type = data.get("audio_gen_type")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    selected_voice = stats.get("current_voice", "alloy")
    if selected_voice in AVAILABLE_VOICES:
        voice_id = AVAILABLE_VOICES[selected_voice]
    else:
        voice_id = "alloy"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞—É–¥–∏–æ –∑–∞–ø—Ä–æ—Å –∏ —Ç–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    await state.update_data(
        last_audio_prompt=prompt_text,
        audio_gen_type=audio_gen_type
    )

    status_message = await message.answer("üéµ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞—É–¥–∏–æ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ...")
    
    if audio_gen_type == "response":
        # –î–ª—è —Ç–∏–ø–∞ "response" —Å–Ω–∞—á–∞–ª–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        if not stats.get("current_model"):
            await status_message.edit_text(
                "‚ùó –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üìù –¢–µ–∫—Å—Ç'",
                reply_markup=get_main_keyboard()
            )
            await state.clear()
            return

        if stats.get("model_type") != "text":
            await status_message.edit_text(
                "‚ùó –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ 'ü§ñ –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏' -> 'üìù –¢–µ–∫—Å—Ç'",
                reply_markup=get_main_keyboard()
            )
            await state.clear()
            return

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        response = await generate_text(stats["current_model"], prompt_text, None, user_id)
        if not response:
            await status_message.edit_text(
                "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
                reply_markup=get_main_keyboard()
            )
            await state.clear()
            return

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
        text_to_speak = response
        caption = f"üéµ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ\n\n–¢–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {audio_gen_type}\n–ì–æ–ª–æ—Å: {selected_voice}\n\n–¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç:\n{response}"
    else:
        # –î–ª—è —Ç–∏–ø–∞ "echo" –ø—Ä–æ—Å—Ç–æ –æ–∑–≤—É—á–∏–≤–∞–µ–º –≤–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        text_to_speak = prompt_text
        caption = f"üéµ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ\n\n–¢–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {audio_gen_type}\n–ì–æ–ª–æ—Å: {selected_voice}"

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ
    audio_data = await generate_audio("openai-audio", text_to_speak, voice=voice_id)

    if audio_data:
        stats["audio_generated"] = stats.get("audio_generated", 0) + 1
        stats["last_used"] = datetime.now()
        update_user_stats(user_id, stats)

        audio_io = BytesIO(audio_data)
        audio_io.name = "generated_audio.mp3"

        await status_message.edit_text("‚úÖ –ê—É–¥–∏–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –±–µ–∑ –∫–Ω–æ–ø–æ–∫
        await message.answer_audio(
            audio=BufferedInputFile(audio_io.read(), filename=audio_io.name),
            caption=caption
        )
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ–Ω—é –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        await message.answer(
            get_menu_text(user_id),
            reply_markup=get_main_keyboard()
        )
    else:
        await status_message.edit_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            reply_markup=get_main_keyboard()
        )
        await state.clear()

async def cancel_action(callback: types.CallbackQuery, state: FSMContext):
    await state.clear()
    await safe_edit_message(
        callback.message,
        "‚ùå –î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ\n" + get_menu_text(callback.from_user.id),
        reply_markup=get_main_keyboard()
    )
    await callback.answer()

async def back_to_menu_from_generation(callback: types.CallbackQuery, state: FSMContext):
    await state.clear()
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ–Ω—é –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    await callback.message.answer(
        get_menu_text(callback.from_user.id),
        reply_markup=get_main_keyboard()
    )
    await callback.answer()

async def redo_text_generation(callback: types.CallbackQuery, state: FSMContext, bot: Bot):
    user_id = callback.from_user.id
    stats = get_user_stats(user_id)
    model = stats["current_model"]

    data = await state.get_data()
    last_prompt_text = data.get("last_prompt_text")
    last_image_data_bytes = data.get("last_image_data")

    if not last_prompt_text and not last_image_data_bytes:
        await callback.message.answer(
            "–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.",
            reply_markup=get_main_keyboard()
        )
        await state.clear()
        await callback.answer()
        return

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    status_message = await callback.message.answer(
        "üîÑ –ü–µ—Ä–µ–¥–µ–ª—ã–≤–∞—é –æ—Ç–≤–µ—Ç..." +
        ("\nüñº –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..." if last_image_data_bytes else "")
    )

    # –ü–µ—Ä–µ–¥–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Ç–µ–∫—Å—Ç –≤ —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    response = await generate_text(model, last_prompt_text, last_image_data_bytes, user_id)

    if response:
        stats["texts_generated"] += 1 # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
        stats["last_used"] = datetime.now()
        update_user_stats(user_id, stats)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ—Ç–≤–µ—Ç–æ–º –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await callback.message.answer(
            f"‚ú® –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ <b>{model}</b>:\n\n{response}",
            parse_mode="HTML",
            reply_markup=get_generation_response_keyboard()
        )
        # –û—Å—Ç–∞–µ–º—Å—è –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–∂–∏–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞

    else:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await callback.message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            reply_markup=get_main_keyboard()
        )
        await state.clear() # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ

    await callback.answer()

async def choose_voice(callback: types.CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞."""
    await callback.answer()
    await callback.message.edit_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ:",
        reply_markup=get_voice_selection_keyboard()
    )

async def voice_selected(callback: types.CallbackQuery, state: FSMContext):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞."""
    await callback.answer()
    voice_name = callback.data.split(":")[1]
    voice_id = AVAILABLE_VOICES.get(voice_name)
    
    if voice_id:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        await state.update_data(selected_voice=voice_id)
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id = callback.from_user.id
        stats = get_user_stats(user_id)
        stats["current_voice"] = voice_name
        update_user_stats(user_id, stats)
        
        await callback.message.edit_text(
            get_menu_text(user_id),
            reply_markup=get_main_keyboard()
        )
    else:
        await callback.message.edit_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –≥–æ–ª–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            reply_markup=get_voice_selection_keyboard()
        )

async def redo_audio_generation(callback: types.CallbackQuery, state: FSMContext, bot: Bot):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ."""
    data = await state.get_data()
    last_prompt = data.get("last_audio_prompt")
    
    if not last_prompt:
        await callback.message.answer(
            "–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.",
            reply_markup=get_main_keyboard()
        )
        await state.clear()
        await callback.answer()
        return

    user_id = callback.from_user.id
    stats = get_user_stats(user_id)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    selected_voice = stats.get("current_voice", "alloy")
    if selected_voice in AVAILABLE_VOICES:
        voice_id = AVAILABLE_VOICES[selected_voice]
    else:
        voice_id = "alloy"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    status_message = await callback.message.answer("üîÑ –ü–µ—Ä–µ–¥–µ–ª—ã–≤–∞—é –∞—É–¥–∏–æ...")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ –Ω–∞–ø—Ä—è–º—É—é
    audio_data = await generate_audio("openai-audio", last_prompt, voice=voice_id)

    if audio_data:
        stats["audio_generated"] = stats.get("audio_generated", 0) + 1
        stats["last_used"] = datetime.now()
        update_user_stats(user_id, stats)

        audio_io = BytesIO(audio_data)
        audio_io.name = "generated_audio.mp3"

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await callback.message.answer("‚úÖ –ê—É–¥–∏–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –±–µ–∑ –∫–Ω–æ–ø–æ–∫
        await callback.message.answer_audio(
            audio=BufferedInputFile(audio_io.read(), filename=audio_io.name),
            caption=f"üéµ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ\n\n–¢–∏–ø –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {data.get('audio_gen_type')}\n–ì–æ–ª–æ—Å: {selected_voice}"
        )
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ–Ω—é –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        await callback.message.answer(
            get_menu_text(user_id),
            reply_markup=get_main_keyboard()
        )
    else:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        await callback.message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            reply_markup=get_main_keyboard()
        )
        await state.clear()

    await callback.answer()
